**Assignment 5**
Implement K-Means clustering/ hierarchical clustering on sales_data_sample.csv dataset.  
Determine the number of clusters using the elbow method. 
Dataset link : https://www.kaggle.com/datasets/kyanyoga/sample-sales-data

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from scipy.cluster.hierarchy import dendrogram,linkage
from sklearn.cluster import KMeans

df = pd.read_csv("sales_data_sample.csv",encoding = 'ISO-8859-1')

df

df.head()

df.tail()

df.dtypes

df.shape

df.describe()

df.info()

df.isnull().sum()

df.isnull().sum().sum()

df = df.drop("ADDRESSLINE2",axis = 1)


x = df.select_dtypes(include = [np.number])
scaler = StandardScaler()
x_scaled = scaler.fit_transform(x)

#elbow method
inertia = []
for k in range(1,11):
    kmeans = KMeans(n_clusters = k,random_state = 0)
    kmeans.fit(x_scaled)
    inertia.append(kmeans.inertia_)

K = range(1,11)
plt.plot(K,inertia,marker = "o")
plt.xticks(K)
plt.title("Elbow Method for Optimal K")
plt.xlabel("Number of clusters")
plt.ylabel("Inertia (WCSS)")
plt.grid()
plt.show()

optimal_k = 4  # or any number determined by observing the elbow plot
print(f"Optimal number of clusters chosen: {optimal_k}")


#Kmeans clustering
kmeans = KMeans(n_clusters = optimal_k,random_state =0)
kmeans.fit(x_scaled)
clusters = kmeans.predict(x_scaled)

df["Cluster"] = clusters

df

# Hierarchical Clustering and Dendrogram
linked = linkage(x_scaled,'ward')

plt.figure(figsize = (10,7))
dendrogram(linked,orientation = "top",distance_sort = "descending",show_leaf_counts = True)
plt.title("Dendrogram for hierarchical clustering")
plt.xlabel("Samples")
plt.ylabel("Distance")
plt.show()



